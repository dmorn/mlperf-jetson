<!DOCTYPE html ><html xml:lang="en" lang="en" data-highlight-require-whitespace="false" xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html;charset=utf-8" /><meta http-equiv="Content-Style-Type" content="text/css" /><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta http-equiv="X-UA-Compatible" content="IE=edge" /><!-- NVIDIA customization --><title>NVIDIA Jetson Linux Driver Package Software Features : Graphics Programming | NVIDIA Docs </title><link rel="Prev" href="graphics_eglstream_user_guide.html" title="Previous" /><link rel="Next" href="opengl_egl_test_app.html" title="Next" /><link rel="StyleSheet" href="../css/font-awesome/css/font-awesome.css" type="text/css" media="all" /><link rel="StyleSheet" href="css/graphics_opengl.css" type="text/css" media="all" /><link rel="StyleSheet" href="css/webworks.css" type="text/css" media="all" /><link rel="StyleSheet" href="css/skin.css" type="text/css" media="all" /><link rel="StyleSheet" href="css/social.css" type="text/css" media="all" /><link rel="StyleSheet" href="css/print.css" type="text/css" media="print" /><noscript><div id="noscript_padding"></div></noscript></head><body id="pyzcKA_002fgKSFcrgCEf0NsKiw" class="ww_skin_page_body" style="visibility: hidden;"><input type="hidden" id="page_onload_url" value="../index.html#page/Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html"></input><span id="dropdown_ids" style="display:none;"></span><div id="ww_content_container"><header id="wwconnect_header"><div class="ww_skin_page_toolbar"><div id="dropdown_button_container" class="dropdown_container dropdown_button_container_disabled"><a id="show_hide_all" class="ww_skin ww_behavior_dropdown_toggle ww_skin_dropdown_toggle" title="Page DropDown Toggle" href="#"><i class="fa"></i></a><span class="ww_skin_page_toolbar_divider">&nbsp;</span></div><a class="ww_behavior_print ww_skin ww_skin_print" title="Print" href="#"><i class="fa"></i></a></div><!-- was this helpful button --><!--                         --></header><div id="page_content_container" style="background-attachment: scroll; background-image: url(&quot;watermark.png&quot;); background-position: center center; background-repeat: no-repeat; margin-left: 0pt; margin-right: 10pt; padding-bottom: 0px; padding-left: 0px; padding-right: 0px; padding-top: 0px"><div id="page_content"><H1 id="wwpID0E0IH0HA" class="Heading_2_Top">OpenGL ES Programming Tips</H1><div class="WebWorks_MiniTOC"><div class="WebWorks_MiniTOC_Heading">&nbsp;</div><dl class="WebWorks_MiniTOC_List"><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0GH0HA">Programming Efficiently</a></div></dd><dl class="WebWorks_MiniTOC_List"><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0DH0HA">State</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0SG0HA">Geometry</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0NF0HA">Shader Programs</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0LE0HA">Textures</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0HD0HA">Miscellaneous</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E03C0HA">Optimizing OpenGL ES Applications</a></div></dd></dl><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0WC0HA">Avoiding Memory Fragmentation</a></div></dd><dl class="WebWorks_MiniTOC_List"><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0TC0HA">Video Memory Overview</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0LC0HA">Allocating and Freeing Video Memory</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0EXHA">Best Practices for Video Memory Management</a></div></dd></dl><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0EFHA">Graphics Driver CPU Usage</a></div></dd><dd><div class="WebWorks_MiniTOC_Entry"><a class="WebWorks_MiniTOC_Link" href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0ECHA">Performance Guidelines</a></div></dd></dl></div><div id="wwpID0E0HH0HA" class="Body_Text">This topic is for readers who have some experience programming OpenGL ES and want to improve the performance of their OpenGL ES application. It aims at providing recommendations on getting the most out of the API and hardware resources without diving into too many architectural details.</div><H3 id="wwpID0E0GH0HA" class="Heading_3">Programming Efficiently</H3><div id="wwpID0E0FH0HA" class="Body_Text">Some of the recommendations in this topic are incompatible with each other. One must consider the trade-offs between CPU load, memory, bandwidth, shader processing power, precision, and image quality. Premature assumptions about the effectiveness of trade-offs should be avoided. The only definite answers come from benchmarking and looking at rendered images!</div><div id="wwpID0E0EH0HA" class="Body_Text">The items below are not ordered according to importance or potential performance increase. The identifiers in parentheses exist only for reference.</div><H4 id="wwpID0E0DH0HA" class="Heading_4">State</H4><div id="wwpID0E0CH0HA" class="Body_Text">Inefficient management of GL state leads to increased CPU load that may limit the amount of useful work the CPU could be doing elsewhere. Reducing the number of times rendering is paused due to GL state change will increase the chance of realizing the potential throughput of the <span class="Hyperlink">GPU</span>. The main point in this section is: do not modify or query GL state unless absolutely necessarily.</div><div id="wwpID0E0BH0HA" class="Heading_5">Do not set any state redundantly (S1)</div><div id="wwpID0E0AH0HA" class="Body_Text">All relevant GL states should be initialized during application initialization and not in the main render loop. For instance, occasionally <span class="Code_Char">glClearDepthf()</span>, <span class="Code_Char">glColorMask()</span>, or <span class="Code_Char">glViewport()</span> finds its way into the application render loop even though the values passed to these functions are always constant. Other times they are set unconditionally in the loop, just in case their values have changed per frame. Only call these functions when the values actually do need to change. Additionally, do not automatically set state back to some predefined value (e.g., the GL defaults). That idiom might be useful while developing your application as it makes it easier to re-order pieces of rendering code, but it should not be done in production code without a very good reason.</div><div id="wwpID0E06G0HA" class="Heading_5">Avoid querying any GL state in the render loop (S2)</div><div id="wwpID0E05G0HA" class="Body_Text">When a GL context is created, the state is initially well-defined. Every state variable has a default value that is described in the OpenGL ES specification (“State Tables”). Except when compiling shaders, determining available extensions, or the application needs to query implementation specific constants, there should be no need to query any GL state. These queries can almost always be done in initialization. Well-written applications check for GL errors in debug builds. If no errors are reported as a result of changing state, it is assumed that the changes are now part of the new GL state. For these two reasons, the current state is always known, and you should almost never need to query any GL state in a loop. If an application frequently calls functions that begin with <span class="Code_Char">glIs*</span> or <span class="Code_Char">glGet*</span>, these calls should be tracked down and eliminated.</div><div id="wwpID0E04G0HA" class="Heading_5">Batch on shared state (S3)</div><div id="wwpID0E03G0HA" class="Body_Text">An efficient approach to reduce the number of state changes is batching together all draw calls that use the same state (shaders, blending, textures, etc.). For instance, not batching on the shader changes has the form:</div><div id="wwpID0E02G0HA" class="Code">[ <span class="Code_Char">gl</span>UseProgram(21), DrawX1, <span class="Code_Char">gl</span>UseProgram(59), DrawY1, <span class="Code_Char">gl</span>UseProgram(21), DrawX2, <span class="Code_Char">gl</span>UseProgram(59), DrawY2 ]</div><div id="wwpID0E01G0HA" class="Body_Text">Batching on the shaders leads to an improvement (fewer shader changes):</div><div id="wwpID0E0ZG0HA" class="Code">[ <span class="Code_Char">gl</span>UseProgram(21), DrawX1, DrawX2, <span class="Code_Char">gl</span>UseProgram(59), DrawY1, DrawY2 ]</div><div id="wwpID0E0YG0HA" class="Body_Text">It is quite effective to group draw calls based on the shader programs they use. Reprogramming the GPU by switching between shaders is a relatively costly operation. Within each batch, a further optimization can be made by grouping draw calls that use the same uniforms, texture objects and other state. Generating a log of all function calls into the OpenGL ES API is a good approach for revealing poor batching. A tool such as PerfHUDES can conveniently generate this log without rebuilding the GL application; no change to the source code is necessary.</div><div id="wwpID0E0XG0HA" class="Heading_5">Do not repeat per object state when binding (S4)</div><div id="wwpID0E0WG0HA" class="Body_Text">Recall that some state is bound to the object it affects. As that state is stored in the object, you do not need to repeat it when you rebind the object. A very common mistake is setting the texture parameters for filtering and wrapping every time a texture object is bound. Another common mistake is updating uniform variables that have not changed value since the last time the particular shader program was used. In particular, when batching opportunities are limited, repeating per object state generates enormously inefficient GL code that can easily have a measurable impact on framerate.</div><div id="wwpID0E0VG0HA" class="Heading_5">Enable backface culling whenever possible (S5)</div><div id="wwpID0E0UG0HA" class="Body_Text">Always enable face culling whenever the back-faces are not visible. Rendering the back-faces of primitives is often not necessary.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0TG0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0TG0HA" class="Note_Text">The default GL state has backface culling disabled, so this is one state that should almost always be set during application initialization and be left enabled for the application lifetime.</div></td></tr></table></div><H4 id="wwpID0E0SG0HA" class="Heading_4">Geometry</H4><div id="wwpID0E0RG0HA" class="Body_Text">The amount of geometry, as well as the way it is transferred to the GL, can have a very large impact on both CPU and GPU load. If the application sends geometry inefficiently or too frequently, that alone can create a bottleneck on the CPU side that does not give the GPU enough data to work efficiently. Geometry must be submitted in sizable chunks to realize the potential of the GPU. At the same time, geometry should be minimally defined, stored on the server side, and it should be accessed in a way to get the most out of the two GPU caches that exist before and after vertices are transformed.</div><div id="wwpID0E0QG0HA" class="Heading_5">Use indexed primitives (G1)</div><div id="wwpID0E0PG0HA" class="Body_Text">The vertex processing engine contains a cache where previously transformed vertices are stored. It is called Post-TnL vertex cache. Taking full advantage of this cache can lead to very large performance improvement when vertex processing is the bottleneck. To fully utilize it, it is necessary for the GPU to be able to recognize previously transformed vertices. This can only be accomplished by specifying indexed primitives for the geometry. However, for any non-trivial geometry the optimal order of indices will not be obvious to the programmer. If some geometry is complex, and the application bottleneck is vertex processing, then look into computing a vertex order that maximizes the hit ratio of the Post TnL cache. The topic has been thoroughly studied for years and even simple greedy algorithms can provide a substantial performance boost. Good results have been reported with the algorithm described at the below locations.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 41.75pt" cellspacing="0" summary=""><tr><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 341.3pt"><div id="wwpID0EABB0OG0HA" class="Cell_Heading"><span class="Strong">Document</span></div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 60.45pt"><div id="wwpID0EAAB0OG0HA" class="Cell_Heading"><span class="Strong">URL to Latest</span></div></td></tr><tr><td style="background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top"><div id="wwpID0EABA0OG0HA" class="Cell_Text"><span class="Emphasis">Linear-Speed Vertex Cache Optimisation</span>, by Tom Forsyth, RAD Game Tools (28th September 2006)</div></td><td style="background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top"><div id="wwpID0EAAA0OG0HA" class="Cell_Text" style="text-align: center"><span class="Hyperlink"><a href="https://tomforsyth1000.github.io/papers/fast_vert_cache_opt.html" target="external_window">URL</a></span></div></td></tr></table></div><div id="wwpID0E0NG0HA" class="Body_Text">There is a free implementation of the algorithm in a library called <span class="Code_Char">vcacne</span>.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0MG0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0MG0HA" class="Note_Text">The number of vertex attributes and the size of each attribute may determine the efficiency of this cache—it has storage for a fixed number of bytes or active attributes, not a fixed number of vertices. A lot of attribute data per vertex increases the risk of cache misses, resulting in potentially redundant transformations of the same vertices. </div></td></tr></table></div><div id="wwpID0E0LG0HA" class="Heading_5">Reduce vertex attribute size and components (G2)</div><div id="wwpID0E0KG0HA" class="Body_Text">It is important to use an appropriate attribute size and minimize the number of components to avoid wasting memory bandwidth and to increase the efficiency of the cache that stores pre-transformed vertices. This cache is called Pre-TnL vertex cache. For instance, you rarely need to specify attributes in 32‑bit FLOATs. It might be possible to define the object-space geometry using 3 BYTEs per vertex for a simple object, or 3 SHORTs for a more complex or larger object. If the geometry requires floating-point representation, half-floats (available in extension <span class="Code_Char">OES_vertex_half_float.txt</span>) may be sufficient. Per-vertex colors are accurately stored with 3 x BYTEs with a flag to normalize in <span class="Code_Char">VertexAttributePointer</span>. Texture coordinates can sometimes be represented with BYTEs or SHORTs with a flag to normalize (if not tiling).</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0JG0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0JG0HA" class="Note_Text">The exception case that normalizing texture coordinates is not necessary if they are only used to sample a cube map texture. </div></td></tr></table></div><div id="wwpID0E0IG0HA" class="Body_Text">Vertex normals can often be represented with 3 SHORTs (in a few cases, such as for cuboids, even as 3 BYTEs) and these should be normalized. Normals can even be represented with 2 components if the direction (sign) of the normal is implicit, given its length is known to be 1. The remaining coordinate can be derived in a vertex shader (e.g. <span class="Code_Char">z = SQRT(1 - x * x + y * y)</span>) if memory or bandwidth (rather than vertex processing) is a likely bottleneck.</div><div id="wwpID0E0HG0HA" class="Body_Text">An optimal OpenGL ES application will take advantage of any characteristics specific to the geometry. For instance, a smooth sphere uses the normalized vertex coordinates as normal—these are trivially computed in a vertex shader. It is important to benchmark intermediate results to ensure the vertex processing engine is not already saturated. Finally remember, if some attribute for a primitive or a number of primitives is constant for the same draw call, then disable the particular vertex attribute index and set the constant value with <span class="Code_Char">VertexAttrib*()</span> instead of replicating the data.</div><div id="wwpID0E0GG0HA" class="Heading_5">Pack vertex attributes (G3)</div><div id="wwpID0E0FG0HA" class="Body_Text">Vertex attributes normally have different sets of attributes that are completely unrelated. Unlike uniform and varying variables in shader programs, vertex attributes do not get automatically packed, and the number of vertex attributes is a limited resource. Failure to pack these attributes together may lead to limitations sooner than expected. It is more efficient to pack the components into fewer attributes even though they may not be logically related. For instance, if each vertex comes with two sets of texture coordinates for multi-texturing, these can often be combined these into one attribute with four components instead of two attributes with two components. Unpacking and swizzling components is rarely a performance consideration.</div><div id="wwpID0E0EG0HA" class="Heading_5">Choose an appropriate vertex attribute layout (G4)</div><div id="wwpID0E0DG0HA" class="Body_Text">There are two commonly used ways of storing vertex attributes:</div><div id="wwpID0E0CG0HA" class="List_Bullet"><span class="WebWorks_Number" style="width: 18pt"><span>•	</span></span>Array of structures</div><div id="wwpID0E0BG0HA" class="List_Bullet"><span class="WebWorks_Number" style="width: 18pt"><span>•	</span></span>Structures of arrays</div><div id="wwpID0E0AG0HA" class="Body_Text">An <span class="Strong">array of structures</span> stores the attributes for a given vertex sequentially with an appropriate offset for each attribute and a non-zero stride. The stride is computed from the number of attribute components and their sizes. An array of structures is the preferred way of storing vertex attributes due to more efficient memory access. If the vertex attributes are constant (not updated in the render loop) there is no question that an array of structures is the preferred layout.</div><div id="wwpID0E06F0HA" class="Body_Text">In contrast, a <span class="Strong">structure of arrays</span> stores the vertex attributes in separate buffers using the same offset for each attribute and a stride of zero. This layout forces the GPU to jump around and fetch from different memory locations as it assembles the needed attributes for each vertex. The structure of arrays layout is therefore less efficient than an array of structures in most cases. The only time to consider a structure of arrays layout is if one or more attributes must be updated dynamically. Strided writes in array of structures can be expensive relative to the number of bytes modified. In this scenario, the recommendation is to partition the attributes such that constant and dynamic attributes can be read and written sequentially, respectively. The attributes that remain constant should be stored in an array of structures. The attributes that are updated dynamically should be stored in smaller separate buffer objects (or perhaps just a single buffer if the attributes are updated with the same frequency).</div><div id="wwpID0E05F0HA" class="Heading_5">Use consistent winding (G5)</div><div id="wwpID0E04F0HA" class="Body_Text">The geometry winding (clockwise or counter-clockwise) should be determined up front and defined in code. The geometry face that is culled by GL can be changed with <span class="Code_Char">glFrontFace()</span>, but having to switch back and forth between winding for different geometry batches during rendering is not optimal for performance and can be avoided in most cases.</div><div id="wwpID0E03F0HA" class="Heading_5">Always use vertex and index buffer objects (G6)</div><div id="wwpID0E02F0HA" class="Body_Text">Recall that vertices for geometry can either be sourced from application memory every time it is rendered or from buffers in graphics memory where it has been stored previously. The same applies to vertex array indices. To achieve good performance, you should never continuously source the data from application memory with <span class="Code_Char">glDrawArrays()</span>. Buffer objects should always be used to store both geometry and indices. Check that no code is calling <span class="Code_Char">glDrawArrays()</span>, and that no code is calling <span class="Code_Char">glDrawElements()</span> without a buffer bind.</div><div id="wwpID0E01F0HA" class="Body_Text">The default buffer usage flag when allocating buffer objects is <span class="Code_Char">STATIC_DRAW</span>. In many cases this will lead to fastest access.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0ZF0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0ZF0HA" class="Note_Text"><span class="Code_Char">STATIC_DRAW</span> does not mean one can never write to the buffer (although any writing to a buffer should always be avoided as much as possible). A <span class="Code_Char">STATIC_DRAW</span> flag may in fact be the appropriate usage flags, even if the buffer contents are updated every few frames. Only after careful benchmarking and arriving at conclusive results should changing the usage flag to one of the alternatives (<span class="Code_Char">DYNAMIC_DRAW</span> or <span class="Code_Char">STREAM_DRAW</span>) be considered. </div></td></tr></table></div><div id="wwpID0E0YF0HA" class="Heading_5">Batch geometry into fewer buffers and draw calls (G7)</div><div id="wwpID0E0XF0HA" class="Body_Text">There are only so many draw calls, or batches of geometry, that can be submitted to GL before the application becomes CPU bound. Each draw call has an overhead that is more or less fixed. Therefore, it is very important to increase the sizes of batches whenever possible. There does not need to be a one-to-one correspondence between a draw call and a buffer—a large vertex buffer can store geometry with a similar layout for multiple models. One or more index buffers can be used to select the subset of vertices needed from the vertex buffer. A common mistake is to have too many small buffers, leading to too many draw calls and thus high CPU load. If the number of draw calls issued in any given frame goes into many hundreds or thousands, then it is time to consider combining similar geometry in fewer buffers and use appropriate offsets when defining the attribute data and creating the index buffer.</div><div id="wwpID0E0WF0HA" class="Body_Text">Unconnected geometry can be stitched together with degenerate triangles (alternatively, by using extension <span class="Code_Char">NV_primitive_restart2</span> when available). Degenerate triangles are triangles where two or more vertices are coincident leading to a null surface. These are trivially rejected and ignored by the GPU. The benefit from stitching together geometry with degenerate triangles, such that fewer and larger buffers are needed, tends to outweigh the minor overhead of sending degenerates triangles down the pipeline. If geometry batches are being broken up to bind different textures, then look at combining several images into fewer textures (T5).</div><div id="wwpID0E0VF0HA" class="Heading_5">Use the smallest possible data type for indices (G8)</div><div id="wwpID0E0UF0HA" class="Body_Text">When the geometry uses relatively few vertices, an index buffer should specify vertices using only <span class="Code_Char">UNSIGNED_BYTE</span> instead of <span class="Code_Char">UNSIGNED_SHORT</span> (or an even larger integer type if the ES2 implementation supports it). Count the number of unique vertices per buffer and choose the right data type. When batching geometry for several unrelated models into fewer buffer objects (G7), then a larger data type for the indices may be required. This is not a concern compared to the larger performance benefits of batching.</div><div id="wwpID0E0TF0HA" class="Heading_5">Avoid allocating new buffers in the rendering loop (G9)</div><div id="wwpID0E0SF0HA" class="Body_Text">If the application frequently updates the geometry, then allocate a set of sufficiently large buffers when the application initializes. A <span class="Code_Char">glBufferData()</span> call with a NULL data pointer will reserve the amount of memory you specify. This eliminates the time spent waiting for an allocation to complete in the rendering loop. Reusing pre-allocated buffers also helps to reduce memory fragmentation.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0RF0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0RF0HA" class="Note_Text">Writing to a buffer object that is being used by the GPU can introduce bubbles in the pipeline where no useful work is being done. To avoid reducing throughput when updating buffers, consider cycling between multiple buffers to minimize the possibility of updating the buffer from which content is currently being rendered. </div></td></tr></table></div><div id="wwpID0E0QF0HA" class="Heading_5">Cull early and often (G10)</div><div id="wwpID0E0PF0HA" class="Body_Text">The GPU will not rasterize primitives when all of its vertices fall outside the viewport. It also avoids processing hidden fragments when the depth test or stencil test fails (P4). However, this does not mean that the GPU should do all the work in deciding what is visible. In the case of vertices, they need to be loaded, assembled and processed in the vertex shader, before the GPU can decide whether to cull or clip parts of the geometry. Testing a single, simple bounding volume that encloses the geometry against the current view frustum on the CPU side is a lot faster than testing hundreds of thousands of vertices on the GPU. If an application is limited by vertex processing, this is definitely the place to begin optimizing. Spheres are the most efficient volumes to test against and the volume of choice if geometry is rotational symmetrical. For some geometry, spheres tend to lead to overly conservative visibility acceptance. A rectangular cuboid (box) is only a slightly more expensive test but can be made to fit more tightly on most geometry. Hierarchical culling can often be employed to reduce the number of tests necessary on the CPU. Efficient and advanced culling algorithms have been heavily researched and published for many years. You can find a good introduction in the survey at the below locations.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 41.75pt" cellspacing="0" summary=""><tr><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 341.3pt"><div id="wwpID0EABB0OF0HA" class="Cell_Heading"><span class="Strong">Document</span></div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 60.45pt"><div id="wwpID0EAAB0OF0HA" class="Cell_Heading"><span class="Strong">URL to Latest</span></div></td></tr><tr><td style="background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top"><div id="wwpID0EABA0OF0HA" class="Cell_Text"><span class="Emphasis">Visibility in Computer Graphics</span>, by Jiří Bittner and Peter Wonka</div></td><td style="background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top"><div id="wwpID0EAAA0OF0HA" class="Cell_Text" style="text-align: center"><span class="Hyperlink"><a href="http://www.cg.tuwien.ac.at/research/publications/2003/Bittner-2003-VCG/TR-186-2-03-03Paper.pdf" target="external_window">URL</a></span></div></td></tr></table></div><H4 id="wwpID0E0NF0HA" class="Heading_4">Shader Programs</H4><div id="wwpID0E0MF0HA" class="Body_Text">Writing efficient shaders is critical to achieving good performance. One should treat shaders like pieces of code that run in the inner-most loops on a CPU. There is a very high cost to littering these with conditionals or recomputing loop invariants. Before optimizing an expensive vertex shader, make sure geometry that is entirely outside the view frustum is being culled on the CPU. Before optimizing an expensive fragment shader, make sure the application is not generating an excess number of fragments with it.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0LF0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0LF0HA" class="Note_Text">When optimizing shaders, any source code that does not contribute to its output variables is optimized out by the compiler. This feature can be exploited to gain knowledge about whether the shader is part of the current bottleneck by multiplying the output variable with a null vector to reduce the workload and then measure if frame rate improves. Conversely, at the final stages of optimization one can quickly measure if there is headroom for increasing workload to offload computations to shader unit or to improve image quality by adding meaningless but expensive ALU instructions, or texture sampling, to the output variables. </div></td></tr></table></div><div id="wwpID0E0KF0HA" class="Heading_5">Move computations up the pipeline (P1)</div><div id="wwpID0E0JF0HA" class="Body_Text">As the rendering pipeline is traversed from the CPU to the vertex processor and then to the fragment processor, the required workload tends to increase a few orders of magnitude each time. Computations constant per model, per primitive or per vertex do not belong in the fragment processor and should be moved up to the vertex processor or earlier. Per draw call computations do not belong in the vertex processor and should be moved to the CPU. For instance, if lighting is done in eye-space, the light vector should be transformed into eye-space and stored in a uniform rather than repeating this for each vertex or, even worse, per fragment. The light vector should naturally be stored pre-normalized. Usually the light vector computations are constant for the draw call, so they do not belong in any shader.</div><div id="wwpID0E0IF0HA" class="Heading_5">Do not write large or generalized shaders (P2)</div><div id="wwpID0E0HF0HA" class="Body_Text">It is critical to resist the temptation to write shader programs that take different code paths depending on whether one or more constant variable have a particular value. Uniforms are intended as constants for one (or hopefully many) primitives—they are not substitutes for calling <span class="Code_Char">glUseProgram()</span>. Shaders should be minimal and specialized to the task they perform. It is much better to have many small shaders that run fast than a few large shaders that all run slow. Code re-use (when source shaders are supported) should be handled at the application level using <span class="Code_Char">glShaderSource()</span>. If the advice here of not writing generalized shaders goes against the conflicting goal of minimizing shader and state changes, smaller and more specialized shaders are generally preferred. Additionally, be careful with writing shader functions intended for concatenation into the final shader source code - shared functions tend to be overly generic and make it harder to exploit possible shortcuts.</div><div id="wwpID0E0GF0HA" class="Heading_5">Take advantage of application specific knowledge (P3)</div><div id="wwpID0E0FF0HA" class="Body_Text">Application specific knowledge can be used to simplify or avoid computations. Math shortcuts should be pursued everywhere because there are optimizations that the shader compiler or the GPU cannot make. For instance, rendering screen-aligned primitives is common for 2D user interface and post-processing effects. In this case, the entire <span class="Code_Char">modelview</span> transformation is avoided by defining the vertices in NDC (normalized device coordinates). A full-screen quad has its vertex coordinates in the [-1.0,1.0] range so these can be passed directly from the vertex attribute to <span class="Code_Char">gl_Position</span>. The types of matrix transformations applied in the application when creating the <span class="Code_Char">modelview</span> matrix should be tracked and exploited when possible. For instance, an orthonormal matrix (e.g. no non-uniform scaling) leads to an opportunity to avoid computations when transforming normals with the inverse-transpose sub-matrix.</div><div id="wwpID0E0EF0HA" class="Heading_5">Optimize for depth and stencil culling (P4)</div><div id="wwpID0E0DF0HA" class="Body_Text">The GPU can quickly reject fragments based on depth or stencil testing before the fragment shader is executed. The depth complexity of a scene is the number of times each fragment gets written. Depth complexity can be measured by incrementing values in a stencil buffer. A high depth complexity in a 3D scene can be a result of rendering opaque objects in a non-optimal order. The worst case is rendering back-to-front (aka painter's algorithm) because it leads to a large number of fragments being overdrawn. An application with high depth complexity should ensure that opaque objects are rendered sorted front-to-back order with depth testing enabled. Straightforward rendering of 2D user interfaces also leads to a high depth complexity that can often be decreased with the same technique but also by using the stencil buffer to mask fragments. Applications that are heavily fragment limited can be sped up significantly with clever use of these techniques—sometimes up to a factor of 10 or more.</div><div id="wwpID0E0CF0HA" class="Body_Text">If vertex processing is not a bottleneck, it is worthwhile to run experiments that prime the depth buffer in a first pass. Disable all color writes with <span class="Code_Char">glColorMask()</span> on the first pass. The fragments in the depth buffer can then serve as occluders in a second pass when color writes are enabled, and the expensive fragment shaders are executed. Disable depth writes with <span class="Code_Char">glDepthMask()</span> in the second pass since there is no point in writing it twice.</div><div id="wwpID0E0BF0HA" class="Heading_5">Do not discard fragments, or modify depth, unless absolutely necessary (P5)</div><div id="wwpID0E0AF0HA" class="Body_Text">Some operations prevent the hardware from enabling its automatic optimization that rejects fragments early in the pipeline (early-Z). In particular, the <span class="Code_Char">discard</span> operation that discards fragments based on some criteria will disable early-Z on some platforms. It is critical to limit the use of discarding as much as possible (e.g., alpha testing)—unless depth writing can be disabled. Another example is found in the <span class="Code_Char">GL_NV_fragdepth</span> extension available on some platforms, where the depth value can be written from the fragment shader. This operation also forces the GPU to opt out of Early-Z reject in order to ensure correct rendering.</div><div id="wwpID0E06E0HA" class="Heading_5">Avoid conditionals in shaders when possible (P6)</div><div id="wwpID0E05E0HA" class="Body_Text">Fragments are processed in chunks and both branches of a conditional may need to be evaluated before the result of the false branch can be discarded by the GPU. Be careful with assuming that conditionals skip computations and reduce the workload. This warning is particularly relevant to fragment shaders. Benchmarking shaders can determine if conditionals in the vertex or fragment shaders actually end up decreasing the workload. Some conditional code can be rewritten in terms of algebra and/or built-in functions. For instance, the dot product between a normal and a light vector may be negative in which case the result is not needed in a lighting equation. Instead of:</div><div id="wwpID0E04E0HA" class="Code">if (nDotL &gt; 0.0) ...</div><div id="wwpID0E03E0HA" class="Body_Text">the value can be clamped with:</div><div id="wwpID0E02E0HA" class="Code">clamp(nDotL, 0.0, 1.0)</div><div id="wwpID0E01E0HA" class="Body_Text">and unconditionally used in the result (the negative value results in a zero-product). Clamp may be faster than max and/or min for the 0.0 and 1.0 cases, but as always benchmarking will have the final say in the matter. Another reason to make an effort of avoiding conditionals in fragment shaders is that mipmapped textures return undefined results when executed in a block statement that is conditional on run-time values. Although the GLSL functions <span class="Code_Char">texture*Lod()</span> can be used to bias or specify the mipmap LOD, it is expensive to manually derive the mipmap LOD. In addition, these LOD biasing samplers may not run as fast as the non-LOD samplers.</div><div id="wwpID0E0ZE0HA" class="Heading_5">Use appropriate precision qualifiers (P7)</div><div id="wwpID0E0YE0HA" class="Body_Text">Recall that the default precision in vertex shaders is <span class="Code_Char">highp</span>, and that fragment shaders have no default precision until explicitly set. Precision qualifiers can be valuable hints to the compiler to reduce register pressure and may improve performance for several reasons. Low precision may run twice as fast in hardware as high precision. These optimizations can be approached by initially using highp and gradually reducing the precision to <span class="Code_Char">lowp</span> until rendering artifacts appear; if it looks good enough, then it is good enough. As a rule of thumb, vertex position, exponential and trigonometry functions need highp. Texture coordinates may need anything from lowp to highp depending on texture width and height. Many application-defined uniform variables, interpolated colors, normals and texture samples can usually be represented using lowp. However, floating-point texture samplers need more than low precision - this is one of several reasons to minimize the use of floating-point textures (T6).</div><div id="wwpID0E0XE0HA" class="Heading_5">Use the built-in functions and variable (P8)</div><div id="wwpID0E0WE0HA" class="Body_Text">The built-ins have a higher chance of compiling optimally and may even be implemented in hardware. For instance, do not write shader code to determine the forward primitive face or compute the reflection vector in terms of dot-products and algebra; instead, use the built-in variable <span class="Code_Char">gl_FrontFacing</span> or the built-in function reflect, respectively.</div><div id="wwpID0E0VE0HA" class="Heading_5">Consider encoding complex functions in textures (P9)</div><div id="wwpID0E0UE0HA" class="Body_Text">Shaders normally contain both arithmetic (ALU) and texture operations. A batch of ALU operations may hide the latency of fetching samples from texture because they occur in parallel. If a shader is the primary bottleneck, and when the ALU operations significantly outnumber the texture operations, it is worthwhile to investigate if some of these operations can be encoded in textures. Sub-expressions in shaders can sometimes be stored in LUTs (look-up-tables). LUTs can sometimes be implemented in textures with sufficient precision and accessed as 1D or 2D textures with NEAREST filtering.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0TE0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0TE0HA" class="Note_Text">The old trick of using cubemaps to normalize vectors is most likely a performance loss on discrete GPUs. If you pursue this idea, then make sure to benchmark to determine if you have improved or worsened the performance! </div></td></tr></table></div><div id="wwpID0E0SE0HA" class="Heading_5">Limit the amount of indirect texturing (P10)</div><div id="wwpID0E0RE0HA" class="Body_Text">Indirect texturing can sometimes be useful, but when the result of a texture operation depends on another texture operation, the latency of texture sampling is difficult to hide. It also tends to lead to scattered reads that minimize the benefit of the texture cache. Indirect texturing can sometimes be reduced, or avoided, at the expense of memory. Whether that trade-off makes sense should of course be analyzed and benchmarked.</div><div id="wwpID0E0QE0HA" class="Heading_5">Do not let GLSL syntax obscure math optimizations (P11)</div><div id="wwpID0E0PE0HA" class="Body_Text">The GLSL shading language conveniently overloads arithmetic operators for vectors and matrices. Care must be taken to not miss optimization opportunities due to this syntax simplification. For instance, a rotation matrix can, but should not, be defined as homogenous 4x4 matrix just because the other operand is a vec4 vector. A generalized rotation matrix should be described only as a 3&nbsp;x&nbsp;3 matrix and applied to vec3 vectors. And a rotation around basic vectors can be done even more efficiently than <span class="Code_Char">mat3 * vec3</span> by directly accessing the relevant vector and matrix components with cos and sin. Take advantage of any specific application knowledge to reduce the number of needed scalar instructions.</div><div id="wwpID0E0OE0HA" class="Heading_5">Only normalize vectors when it is necessary (P12)</div><div id="wwpID0E0NE0HA" class="Body_Text">Normalization of vectors is required to efficiently calculate the angle between them, or perhaps more typically, the diffuse component in many commonly used lighting equations. In theory, normalization is required for geometry normals after having transformed them with the normal matrix. In practice, it may not matter depending on the composition of the matrix. It is a common mistake to normalizing vectors where it is not necessary, or at least not visually discernible. As a result, the application may run slower for no good reason. For instance, consider the case of interpolating vertex normals in order to compute lighting per fragment (i.e., Phong shading). If the normal matrix only rotates, there is little reason to normalize the normal vectors before interpolating.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0ME0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0ME0HA" class="Note_Text">Barycentric interpolation will not preserve the unit length of these vectors. So normals that are interpolated in varying variables do must be normalized to ensure the dot-product with the light vector obeys the cosine emission law. </div></td></tr></table></div><H4 id="wwpID0E0LE0HA" class="Heading_4">Textures</H4><div id="wwpID0E0KE0HA" class="Body_Text">Textures consume the largest amount of the available memory and bandwidth in many applications. One of the best places to look for improvements when short on memory or bandwidth to optimize texture size, format and usage. Careless use of texturing can degrade the frame rate and can even result in inferior image quality.</div><div id="wwpID0E0JE0HA" class="Heading_5">Use texture compression whenever possible (T1)</div><div id="wwpID0E0IE0HA" class="Body_Text">Texture compression brings several benefits that result from textures taking up less memory: compressed textures use less of the available memory bandwidth, reduces download time, and increases the efficiency of the texture cache. The <span class="Code_Char">texture_compression_s3tc</span> and <span class="Code_Char">texture_compression_latc</span> extensions both provide block-based lossy texture compression that can be decompressed efficiently in hardware. The S3TC extension gives 8:1 or 4:1 compression ratio and is suitable for color images with 3 or 4 channels (with or without alpha) with relatively low-frequency data. Photographs and other images that compress satisfactory with JPEG are great candidates for S3TC. Images with hard and crisp edges are poorer candidates for S3TC and may appear slightly blurred and noisy. The LATC extension yields a 2:1 compression ratio, but improves on the quality, and can be useful for high resolution normal maps. The third coordinate is derived in the fragment shader—be sure to benchmark if the application can afford this trade-off between memory and computations! Unlike S3TC, the channels in LATC are compressed separately, and quantization is less hard. Using texture compression does not always result in lower perceived image quality, and with these extensions one can experiment with increasing the texture resolution for the same memory. There are off-line tools to compress textures (even if a GL extension supports compressing them on-the-fly). Search the NVIDIA developer website for “Texture Tools.”</div><div id="wwpID0E0HE0HA" class="Heading_5">Use mipmaps when appropriate (T2)</div><div id="wwpID0E0GE0HA" class="Body_Text">Mipmaps should be used when there is not an obvious one-to-one mapping between texels and framebuffer pixels. If texture minification occurs in a scene and there are no mipmaps to access, texture cache utilization will be poor due to the sparse sampling. If texture minification occurs more often than not, then the texture size may be too large to begin with. Coloring the mipmap levels differently can provide a visual clue to the amount of minification that is occurring. When reducing the texture size, it may also be worthwhile to perform experiments to see if some degree of magnification is visually acceptable and if it improves frame rate.</div><div id="wwpID0E0FE0HA" class="Body_Text">Although <span class="Code_Char">glGenerateMipmap()</span> is convenient, it should not be the only option for generating a mipmap chain. This function emphasizes execution speed over image quality by using a simple box filter. Generating mipmaps off-line using more advanced filters (e.g. Lanczos/Sinc) will often yield improved image quality at no extra cost. However, <span class="Code_Char">glGenerateMipmap()</span> may be preferable when generating textures dynamically due to speed. One of the only situations where you do not want to use mipmaps is if there is always a one-to-one mapping between texels and pixels. This is sometimes the case in 3D, but more often the case for 2D user interfaces. Recall that a mipmapped texture takes up 33% more storage than un-mipmapped, but they can provide much better performance and even better image quality through reduced aliasing.</div><div id="wwpID0E0EE0HA" class="Heading_5">Use the smallest possible textures size (T3)</div><div id="wwpID0E0DE0HA" class="Body_Text">Always use the smallest possible texture size for any content that gives acceptable image quality. The appropriate size of a texture should be determined by the size of the framebuffer and the way the textured geometry is projected onto it. But even when you have a one-to-one mapping between texels and framebuffer pixels, there may be cases where a smaller size can be used. For instance, when blending a texture on the existing content in the entire framebuffer, the texture does not necessarily have to be the same width and height as the framebuffer. It may be the case that a significantly smaller texture that is magnified will produce results that are good enough. The bandwidth that is saved from using a smaller and more appropriately sized texture can instead be spent where it actually contributes to better image quality or performance.</div><div id="wwpID0E0CE0HA" class="Heading_5">Use the smallest possible texture format and data type (T4)</div><div id="wwpID0E0BE0HA" class="Body_Text">If hardware accelerated texture compression cannot be used for some textures, then consider using a texture format with fewer components and/or fewer bits per component. Textures for user interface elements sometimes have hard edges or color gradients that result in inferior image quality when compressed. The S3TC algorithm make assumptions that changes are smooth and colors values can be quantized. If these assumptions do not fit a particular image, but the number of unique colors is still low, then experiment with storing these in a packed texture format using 16 bit/texel (e.g. <span class="Code_Char">UNSIGNED_SHORT_5_6_5</span>). Although the colors are remapped with less accuracy it may not be noticeable in the final application. Grayscale images should be stored as <span class="Code_Char">LUMINANCE</span> and tinted images can sometimes be stored the same way with the added cost of a dot product with the tint color. If normal maps do not compress satisfactory with the <span class="Code_Char">LATC</span> format, then it may be possible to store two of the normals coordinates in uncompressed <span class="Code_Char">LUMINANCE_ALPHA</span> and derive the third in a shader assuming the direction (sign) of the normal is implicit (as is the case of a heightmap terrain).</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0AE0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0AE0HA" class="Note_Text">When optimizing uncompressed textures, the exception case that 24-bit (RGB) textures are not necessarily faster to download or smaller in memory than 32-bit (RGBA) on most GPUs. In this case, it may be possible to use the last component for something useful. For instance, if there already is an 8-bit greyscale texture that is needed at the same time as an opaque color texture, that single component texture can be stored in the unused alpha component of a 32-bit (RGBA). The component could define a specular/reflectance map that describe where and to what degree light is reflected. This is useful for terrain satellite imagery or land cover textures with water/snow/ice areas or for car textures with their metal and glass surfaces or for textures for buildings with glass windows. </div></td></tr></table></div><div id="wwpID0E06D0HA" class="Heading_5">Store multiple images in each texture object (T5)</div><div id="wwpID0E05D0HA" class="Body_Text">There is no requirement that there is a one-to-one mapping between an image and a texture object. Textures objects can contain multiple distinct images. These are sometimes referred to as a “texture atlas” or a “texture page.” The geometry defines texture coordinates that only reference a subset of the texture. Texture atlases are useful for minimizing state changes and enables larger batches when rendering. For example, residential houses and office buildings and factories might all use distinct texture images. But the geometry and vertex layout for each is most likely identical so these could share the same buffer object. If the distinct images are stored in a texture atlas instead of as separate textures, then these different kinds of buildings can all be rendered more efficiently in the same draw call (G7). The texture object could be a 2D texture, a cubemap texture or an array texture.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA04D0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA04D0HA" class="Note_Text">Note that if mipmapping is enabled, the sub-textures in an atlas must have a border wide enough to ensure that smaller mipmaps are not generated using texels from neighboring images. And if texture tiling (<span class="Code_Char">REPEAT</span> or <span class="Code_Char">MIRRORED_REPEAT</span>) is needed for a sub-image then it may be better to store it outside the texture atlas. </div></td></tr></table></div><div id="wwpID0E03D0HA" class="Body_Text">Emulating either wrapping mode in a shader by manipulating texture coordinates is possible, but not free. A cubemap texture can sometimes be useful since wrapping and filtering apply per face, but the texture coordinates used must be remapped to a vec3 which may be inconvenient. If all the sub-images have the same or similar size, format and type (e.g. image icons), the images are a good candidate for the array texture extension if supported. Array textures may be more appropriate here than a 2D texture atlas where mipmapping and wrapping restrictions have to be taken into consideration.</div><div id="wwpID0E02D0HA" class="Heading_5">Float textures are always expensive (T6)</div><div id="wwpID0E01D0HA" class="Body_Text">Textures with a floating-point format should be avoided whenever possible. If these textures are simply being used to represent a larger range of values, it may be possible to replace these with fixed point textures and scaling instructions. For instance, unsigned 16-bit integers cannot even accurately be represented by half-precision floats (FP16). These would have to be stored using single precision (FP32) leading to twice the memory and bandwidth requirements. It might be better to store these values in two components using 8 bits (LA8) and spend ALU instructions to unpack them in a shader.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0ZD0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0ZD0HA" class="Note_Text">Floating-point textures may not support anything better than nearest filtering. </div></td></tr></table></div><div id="wwpID0E0YD0HA" class="Heading_5">Prefer power-of-two (POT) textures in most cases (T7)</div><div id="wwpID0E0XD0HA" class="Body_Text">Although Non-Power-of-Two (NPOT) textures are supported in ES2 they come with a <span class="Code_Char">CLAMP_TO_EDGE</span> restriction on the wrapping mode (unless relaxed by an extension). More importantly, they cannot be mipmapped (unless relaxed by an extension). For that reason, POT textures should be used when there is not significant memory and bandwidth to be saved from using NPOT. However, an NPOT texture may be padded internally to accommodate alignment restrictions in hardware and that the amount of memory saved might not be quite as large as the width and height suggests. As a rule of thumb, only large (i.e., hundreds of texels) NPOT textures will effectively save a significant amount of memory over POT textures.</div><div id="wwpID0E0WD0HA" class="Heading_5">Update textures sparingly (T8)</div><div id="wwpID0E0VD0HA" class="Body_Text">Writing to GPU resources can be expensive—it applies to textures as well. If texture updates are required, then determine if they really need to be updated per frame or if the same texture can be reused for several frames. For environment maps, unless the lighting or the objects in the environment have been transformed (e.g., moved/rotated) sufficiently to invalidate the previous map, the visual difference may not be noticeable, but the performance improvement can be. The same applies to the depth texture(s) used for shadow mapping algorithms.</div><div id="wwpID0E0UD0HA" class="Heading_5">Update textures efficiently (T9)</div><div id="wwpID0E0TD0HA" class="Body_Text">When updating an existing texture, use <span class="Code_Char">glTexSubImage*()</span> instead of re-defining its entire contents with <span class="Code_Char">TexImage</span> when possible.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0SD0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0SD0HA" class="Note_Text">When using <span class="Code_Char">glTexSubImage*()</span> it is important to specify the same texture format and data type with which that the texture object was defined; otherwise, there may be an expensive conversion as texels are being updated. </div></td></tr></table></div><div id="wwpID0E0RD0HA" class="Body_Text">If the application is only updating from a sub-rectangle of pixels in client memory, then remember that the driver has no knowledge about the stride of pixels in your image. When the width of the image rectangle differs from the texture width, this normally requires a loop through single pixel rows calling <span class="Code_Char">glTexSubImage*()</span> repeatedly while updating the client memory offsets with pointer arithmetic. In this case, the <span class="Code_Char">unpack_subimage</span> extension can be used (if supported) to set the <span class="Code_Char">UNPACK_ROW_LENGTH</span> pixelstore parameter to update the entire region with one <span class="Code_Char">glTexSubImage*()</span> call.</div><div id="wwpID0E0QD0HA" class="Heading_5">Partition rendering based on alpha blending/testing (T10)</div><div id="wwpID0E0PD0HA" class="Body_Text">It is sometimes possible to improve performance by splitting up the rendering based on whether alpha blending or alpha testing is required. Use separate draw calls for opaque geometry so these can be rendered with maximum efficiency with blending disabled. Perform other draw calls for transparent geometry with alpha blending enabled, taking into account the draw ordering that transparent geometry requires. As always, benchmarks should be run to determine if this improves or reduces the frame rate since you will be batching less by splitting up draw calls.</div><div id="wwpID0E0OD0HA" class="Heading_5">Filter textures appropriately (T11)</div><div id="wwpID0E0ND0HA" class="Body_Text">Do not automatically set expensive texture filters and enable anisotropic filtering. Remember that nearest-neighbor filtering always fetches one texel, bilinear filtering fetches up to four texels and trilinear fetches up to eight texels. However, it can be incorrect to draw assumptions about the performance cost based on this. Bilinear filtering may not cost four times as much as nearest filtering, and trilinear can be more or less than twice as expensive as bilinear. Even though textures have mipmaps, it does not automatically mean trilinear filtering should be used. That decision should be made entirely from observing the images from the running application. Only then can a judgment be made if any abrupt changes between mipmap levels are visually disturbing enough to justify the cost of interpolating the mipmaps with trilinear filtering. The same applies to anisotropic filtering, which is significantly more expensive and bandwidth intensive than bilinear or trilinear filtering. If the angle between the textured primitives and the projection plane (e.g. near plane) is never very large, there is nothing to be gained from sampling anisotrophically and there is potentially lower performance. Therefore, an application should start off with the simplest possible texture filtering and only enable more expensive filtering after users have inspected the output images. It might be worthwhile to benchmark the changes and take notes along the way. This will provide a better indication of the relative cost of filtering method and if concessions must be made if the performance budget is exceeded.</div><div id="wwpID0E0MD0HA" class="Heading_5">Try to exploit texture tiling (T12)</div><div id="wwpID0E0LD0HA" class="Body_Text">It is common for images to contain the same repeated pattern of pixels. Or an image might repeat a few patterns that are close enough in similarity that they could be replaced with a single pattern without impacting image quality. Tiling textures saves on memory and bandwidth. Some image processing applications can identify repeated patterns and can crop them so they can be tiled infinitely without seams when using textures with the <span class="Code_Char">REPEAT</span> wrap mode. Sometimes even a quarter of a tile or shingle may be sufficient to store while using <span class="Code_Char">MIRRORED_REPEAT</span>. Consider if tiling variation can be restored or achieved with multi-texturing, using for instance a less expensive grey-scale texture that repeats at a different frequency to modulate the texels from the tiled texture.</div><div id="wwpID0E0KD0HA" class="Heading_5">Use framebuffer objects (FBO) for dynamically generated textures (T13)</div><div id="wwpID0E0JD0HA" class="Body_Text">OpenGL ES comes with functions for copying previously rendered pixels from a framebuffer into a texture (<span class="Code_Char">glCopyTexImage()</span>, <span class="Code_Char">glCopyTexSubImage()</span>&nbsp;). These functions should be avoided whenever possible for performance reasons. It is better to bind a framebuffer object with a texture attachment and render directly to the texture. Make sure you check for framebuffer completeness.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0ID0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA0ID0HA" class="Note_Text">Not all pixel formats are color-renderable. Formats with 3 or 4 components in 16 or 32 bits are color-renderable in OpenGL ES 2.0, but LUMINANCE and/or ALPHA may require a fallback to <span class="Code_Char">glCopyTexImage()</span> functions. </div></td></tr></table></div><H4 id="wwpID0E0HD0HA" class="Heading_4">Miscellaneous</H4><div id="wwpID0E0GD0HA" class="Body_Text">This topic contains miscellaneous OpenGL ES programming tips.</div><div id="wwpID0E0FD0HA" class="Heading_5">Avoid reading back the framebuffer contents (M1)</div><div id="wwpID0E0ED0HA" class="Body_Text">Reading back the framebuffer flushes the GL pipeline and limits the amount CPU/GPU parallelism. Reading frequently or in the middle of a frame stalls the GPU and limits the throughput with lower frame rate as a result. If the buffer contents must be read back (perhaps for picking 3D objects in a complex scene), it should be done minimally and scheduled at the beginning of the next frame. In the special case that the application is reading back into a sub-rectangle of pixels in client memory, the <span class="Code_Char">pack_subimage</span> extension (if supported) is very useful. Setting the <span class="Code_Char">PACK_ROW_LENGTH</span> <span class="Emphasis" style="font-style: normal">pixel store</span> parameter will reduce the loop overhead that will otherwise be necessary (T9).</div><div id="wwpID0E0DD0HA" class="Heading_5">Avoid clearing buffers needlessly (M2)</div><div id="wwpID0E0CD0HA" class="Body_Text">If the application always covers the entire color buffer for each frame, then bandwidth can be saved by not clearing it. It is a common mistake to call gl<span class="Code_Char">Clear(GL_COLOR_BUFFER_BIT)</span> when it is not necessary. If only part of the color buffer is modified, then constrain pixel operations to that region by enabling scissor testing and define a minimal scissor box for the region. The same applies to depth and stencil buffers if full screen testing is not needed.</div><div id="wwpID0E0BD0HA" class="Heading_5">Disable blending when it is not needed (M3)</div><div id="wwpID0E0AD0HA" class="Body_Text">Most blending operations require a read and a write to the framebuffer.</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 36pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA06C0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 342pt"><div id="wwpID0EAAA06C0HA" class="Note_Text">Memory bandwidth is often doubled when rendering with blending is enabled. The number of blended fragments should be kept to a minimum—it can drastically speed up the GL application. </div></td></tr></table></div><div id="wwpID0E05C0HA" class="Heading_5">Minimize memory fragmentation (M4)</div><div id="wwpID0E04C0HA" class="Body_Text">Buffer objects and <span class="Code_Char">glTexImage*()</span> functions are effectively graphics memory allocations. Reusing existing buffer objects and texture objects will reduce memory fragmentation. If geometry or textures are generated dynamically, the application should allocate a minimal pool of objects for this purpose during application initialization. It may be that two buffers or textures used in a round-robin fashion are optimal for reducing the risk that the GPU is waiting on the resource. Also, recall that sampling a texture that is being rendered to, at the same time, is undefined. This can be another reason to alternate between objects. For more information, see <span class="Hyperlink"><a href="../Tegra%20Linux%20Driver%20Package%20Development%20Guide/graphics_opengl.html#wwpID0E0TC0HA" title="OpenGL ES Programming Tips">Memory Fragmentation</a></span> in this appendix.</div><H4 id="wwpID0E03C0HA" class="Heading_4">Optimizing OpenGL ES Applications</H4><div id="wwpID0E02C0HA" class="Body_Text">Optimization is an iterative process. It can be time consuming, especially without prior experience determining where bottlenecks tend to occur. Effort should be directed towards the critical areas instead of starting a random place in the rendering code. When the graphics application is complex it may be difficult to know where to start or exactly where optimizations will yield the best return.</div><div id="wwpID0E01C0HA" class="Heading_5">Partition the analysis into manageable chunks</div><div id="wwpID0E0ZC0HA" class="Body_Text">Many rendering applications are complex and consist of hundreds of objects. But usually they consist of logically separate rendering code. For example, a rendered image may consist of roads, buildings, landmarks, points of interest, sky, clouds, buildings, water, terrain, icons, and a 2D user interface. It is helpful to write the GL application such that rendering of each type of object can be disabled easily. This allows easy identification of the most expensive objects when benchmarking and therefore makes optimizing the rendering code more manageable.</div><div id="wwpID0E0YC0HA" class="Heading_5">Become familiar with bottlenecks in the graphics pipeline</div><div id="wwpID0E0XC0HA" class="Body_Text">It is important to begin optimizations by identifying the performance bottlenecks at the different stages in the graphics pipeline. Because the work introduced in the beginning of the pipeline normally affects the work needed at later stages, it often makes sense to work backwards from the end of the pipeline. An introduction to identifying graphics bottlenecks can be found in the GPU Gems book, “Chapter 28. Graphics Pipeline Performance” (Cem Cebenoyan, NVIDIA).</div><H3 id="wwpID0E0WC0HA" class="Heading_3">Avoiding Memory Fragmentation</H3><div id="wwpID0E0VC0HA" class="Body_Text">Memory Fragmentation generally is a bad thing. This is especially true for computer graphics applications. In addition to avoiding system memory fragmentation, a graphics application should strive to avoid video memory fragmentation as well.</div><div id="wwpID0E0UC0HA" class="Body_Text">Fortunately, controlling video memory fragmentation has techniques very similar to those used to avoid system memory fragmentation. Since system memory fragmentation control is fairly well known, this document will only treat system memory issues in passing and focuses on video memory techniques.</div><H4 id="wwpID0E0TC0HA" class="Heading_4">Video Memory Overview</H4><div id="wwpID0E0SC0HA" class="Body_Text">Video memory is much more heterogenous than system memory.</div><div id="wwpID0E0RC0HA" class="Body_Text">NVIDIA video memory allocation algorithms have to take the following into account:</div><div id="wwpID0E0QC0HA" class="List_Bullet"><span class="WebWorks_Number" style="width: 18pt"><span>•	</span></span>There are multiple types of video memory <span class="Strong">types</span>. The number and names of the types vary by GPU model, but GPUs generally have at least two; linear, which is essentially unformatted, and one or more GPU specific types. The GPU tracks different types of memory, and will access and write them differently. The types are important because GPU native types can be faster for a given set of operations; in some GPU architectures, the difference is small, on the order of 10-15%. On others, it can be quite large, more than 100% faster than linear memory.</div><div id="wwpID0E0PC0HA" class="List_Bullet"><span class="WebWorks_Number" style="width: 18pt"><span>•	</span></span>Video memory is often banked, especially for mipmapped textures. In most architecture, alternating mipmap levels for a given texture must be put in separate banks. This separation is mandatory in most NVIDIA GPUs.</div><div id="wwpID0E0OC0HA" class="List_Bullet"><span class="WebWorks_Number" style="width: 18pt"><span>•	</span></span>In addition to the restrictions above, different memory regions have different alignment restrictions, to match host pages, improve DMA performance, or speed up framebuffer scan out. These alignment requirements may be orthogonal to the memory types, adding further complication.</div><div id="wwpID0E0NC0HA" class="List_Bullet"><span class="WebWorks_Number" style="width: 18pt"><span>•	</span></span>The allocator may have other special restrictions that enhance performance, such as distributing allocations to a sequence of different banks to improve allocation speed.</div><div id="wwpID0E0MC0HA" class="List_Bullet"><span class="WebWorks_Number" style="width: 18pt"><span>•	</span></span>These extra constraints complicate the video memory allocator and make allocations much more sensitive to reductions in available video memory. This is the major reason why NVIDIA does not support multiple independent heaps in video memory, instead requiring the application to allocate in such a way as to minimize fragmentation.</div><H4 id="wwpID0E0LC0HA" class="Heading_4">Allocating and Freeing Video Memory</H4><div id="wwpID0E0KC0HA" class="Body_Text">This topic describes considerations for allocating and freeing video memory.</div><div id="wwpID0E0JC0HA" class="Heading_5">Allocating buffers</div><div id="wwpID0E0IC0HA" class="Body_Text">When using OpenGL ES/EGL, there is only a small set of APIs that actually lead to long-term video memory buffer allocation:</div><div id="wwpID0E0HC0HA" class="Code">glBufferData(enum target, sizeiptr size, const void *data, enum usage)</div><div id="wwpID0E0GC0HA" class="Code">&nbsp;</div><div id="wwpID0E0FC0HA" class="Code">glTexImage2D(enum target, int level, int internalFormat, sizei width, sizei height, int border, enum format, enum type, const void *pixels)</div><div id="wwpID0E0EC0HA" class="Code">&nbsp;</div><div id="wwpID0E0DC0HA" class="Code">glCopyTexImage2D(enum target, int level, enum internalformat, int x, int y, sizei width, sizei height, int border)</div><div id="wwpID0E0CC0HA" class="Body_Text">&nbsp;</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 54pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0BC0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 324.9pt"><div id="wwpID0EAAA0BC0HA" class="Note_Text"><span class="Code_Char">glCopyTexImage2D()</span>allocates only when it copies to a null.</div></td></tr></table></div><div id="wwpID0E0AC0HA" class="Body_Text">&nbsp;</div><div id="wwpID0E06B0HA" class="Code">eglCreateWindowSurface(EGLDisplay dpy, EGLConfig config, NativeWindowType win, const EGLint *attrib_list)</div><div id="wwpID0E05B0HA" class="Code">&nbsp;</div><div id="wwpID0E04B0HA" class="Code">eglCreatePbufferSurface(EGLDisplay dpy, EGLConfig config, const EGLint *attrib_list)</div><div id="wwpID0E03B0HA" class="Code">&nbsp;</div><div id="wwpID0E02B0HA" class="Code">eglCreatePixmapSurface(EGLDisplay dpy, EGLConfig config, NativePixmapType pixmap, const EGLint *attrib_list)</div><div id="wwpID0E01B0HA" class="Heading_5">Freeing buffers</div><div id="wwpID0E0ZB0HA" class="Body_Text">A similar set of APIs free allocated video memory buffers, whether they are textures, VBOs, or surfaces:</div><div id="wwpID0E0YB0HA" class="Code">glDeleteBuffers(sizei n, uint *buffers)</div><div id="wwpID0E0XB0HA" class="Code">&nbsp;</div><div id="wwpID0E0WB0HA" class="Code">glDeleteTextures(sizei n const uint *textures)</div><div id="wwpID0E0VB0HA" class="Code">&nbsp;</div><div id="wwpID0E0UB0HA" class="Code">eglDestroySurface(EGLDisplay dpy, EGLSurface surface)</div><div class="ww_skin_page_overflow"><table class="Table_Normal" style="margin-left: 54pt" cellspacing="0" summary=""><tr><td style="background-color: #76B900; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 49.5pt"><div id="wwpID0EABA0TB0HA" class="Note_Image">Note:</div></td><td style="background-color: #DDEEBF; background-position: right center; border-bottom-color: Silver; border-bottom-style: solid; border-bottom-width: thin; border-left-color: Silver; border-left-style: solid; border-left-width: thin; border-right-color: Silver; border-right-style: solid; border-right-width: thin; border-top-color: Silver; border-top-style: solid; border-top-width: thin; padding-bottom: 3pt; padding-left: 3pt; padding-right: 3pt; padding-top: 3pt; vertical-align: top; width: 324.9pt"><div id="wwpID0EAAA0TB0HA" class="Note_Text"><span class="Code_Char">glDeleteTextures()</span> works only if the texture object is greater than zero; the default texture can't be explicitly deleted (although it can be replaced with a texture containing one or two dimensions of zero, which accomplishes the same thing). </div></td></tr></table></div><div id="wwpID0E0SB0HA" class="Body_Text">Conceptually, these calls can be thought of as <span class="Code_Char">malloc()</span> and <span class="Code_Char">free()</span> for VBOs and texture maps, respectively. The same techniques for avoiding fragmentation can also be applied.</div><div id="wwpID0E0RB0HA" class="Heading_5">Updating a Subregion of a Buffer</div><div id="wwpID0E0QB0HA" class="Body_Text">In many cases, avoiding fragmentation means placing multiple objects into the same shared buffer, or reusing a buffer by deleting or overwriting an older object with a newer one. OpenGL ES provides a method for updating an arbitrary section of allocated VBOs, textures, and surfaces:</div><div id="wwpID0E0PB0HA" class="Code">glBufferSubData(enum target, intptr offset, sizeiptr size, const void *data, enum usage)</div><div id="wwpID0E0OB0HA" class="Code">&nbsp;</div><div id="wwpID0E0NB0HA" class="Code">glTexSubImage2D(enum target, int level, int xoffset, int yoffset, sizei width, sizei height, enum format, enum type, const void *pixels)</div><div id="wwpID0E0MB0HA" class="Code">&nbsp;</div><div id="wwpID0E0LB0HA" class="Code">glCopyTexSubImage2D(enum target, int level, int xoffset, int yoffset, int x, int y, sizei width, sizei height)</div><div id="wwpID0E0KB0HA" class="Code">&nbsp;</div><div id="wwpID0E0JB0HA" class="Code">glScissor(int left, int bottom, sizei width, sizei height);</div><div id="wwpID0E0IB0HA" class="Code">&nbsp;</div><div id="wwpID0E0HB0HA" class="Code">glViewport(int x, int y, sizei w, sizei h)</div><div id="wwpID0E0GB0HA" class="Body_Text"><span class="Code_Char">glTexSubImage2D()</span> and <span class="Code_Char">glCopyTexSubImage2D()</span>update a subregion of the target texture image. In the first case, the source comes from an application buffer; in the second, from a rendering surface.</div><div id="wwpID0E0FB0HA" class="Body_Text"><span class="Code_Char">glScissor()</span> and <span class="Code_Char">glViewport()</span>limit rendering to a subregion of a rendering surface. The first specifies the region of the buffer that <span class="Code_Char">glClear()</span>will affect; the second updates the transforms to limit rendered OpenGL ES primitives to the specified subregion.</div><div id="wwpID0E0EB0HA" class="Heading_5">Using a Buffer Subregion</div><div id="wwpID0E0DB0HA" class="Body_Text">Completing the functionality needed to reuse allocated buffers is the ability to use an arbitrary subregion of a texture, VBO, or surface:</div><div id="wwpID0E0CB0HA" class="Code">glDrawArrays(enum mode, int first, sizei count)</div><div id="wwpID0E0BB0HA" class="Code">&nbsp;</div><div id="wwpID0E0AB0HA" class="Code">glReadPixels(int x, int y, sizei width, sizei height, enum format, enum type, void *data)</div><div id="wwpID0E6HA" class="Code">&nbsp;</div><div id="wwpID0E5HA" class="Code">glCopyTexImage2D(enum target, int level, int x, int y, sizei width, sizei height)</div><div id="wwpID0E4HA" class="Code">&nbsp;</div><div id="wwpID0E3HA" class="Code">glCopyTexSubImage2D(enum target, int level, int xoffset, int yoffset, int x, int y, sizei width, sizei height)</div><div id="wwpID0E2HA" class="Body_Text">For VBOs, <span class="Code_Char">glDrawArrays()</span> allows the application to choose a contiguous subset of a VBO.</div><div id="wwpID0E1HA" class="Body_Text">For textures, there's no explicit call to limit texturing source to a particular subregion. But texture coordinates and wrapping modes can be specified in order to render an arbitrary subregion of texture object.</div><div id="wwpID0EZHA" class="Body_Text">For surfaces, <span class="Code_Char">glReadPixels()</span> can be used to read from a subregion of a display, when copying data back to an application-allocated buffer.</div><div id="wwpID0EYHA" class="Body_Text"><span class="Code_Char">glCopyTexImage2D()</span> and <span class="Code_Char">glCopyTexSubImage2D()</span>also restrict themselves to copying from a subregion of the display surface when transferring data to a texture map. The only area that's problematic is controlling the direct display of window surface back buffer. OpenGL ES and EGL have no way to show only a subregion of the backbuffer surface, but the native windowing systems may have this functionality.</div><H4 id="wwpID0EXHA" class="Heading_4">Best Practices for Video Memory Management</H4><div id="wwpID0EWHA" class="Body_Text">The following is a list of good practices when allocating video memory to avoid or minimize fragmentation:</div><div id="wwpID0EVHA" class="Heading_5">1. Allocate large buffers early</div><div id="wwpID0EUHA" class="Body_Text">Ideally allocate large buffers at the start of the program. On average, allocating large surfaces gets more difficult as more allocations occur. When more allocations occur, free space is broken into smaller pieces.</div><div id="wwpID0ETHA" class="Heading_5">2. Combine many small allocations into a smaller number of larger allocations</div><div id="wwpID0ESHA" class="Body_Text">Small allocations can disproportionately reduce available free space. Not only does the allocator have a fixed overhead per allocation, regardless of size, but small allocations tend to break up large areas of free space into smaller pieces.</div><div id="wwpID0ERHA" class="Body_Text">The ability to load a subregion of a VBO or texture map, and the ability to render that subregion independently, makes it possible to combine VBOs and textures together. For textures, a large texture can be used to hold a grid of smaller images. For VBOs, multiple vertex arrays can be combined end to end into a larger one. Besides reducing fragmentation, combining related images into a single texture, and related vertex arrays into a single VBO often improves rendering time, since it reduces the number of <span class="Code_Char">glBindBuffer()</span> or <span class="Code_Char">glBindTexture()</span> calls required to render a set of related objects.</div><div id="wwpID0EQHA" class="Heading_5">3. Reduce the variation in size of allocated buffers ideally to a single size</div><div id="wwpID0EPHA" class="Body_Text">Allocating buffers of varying sizes, especially sizes that aren't small multiples of each other, is disruptive of memory space and causes fragmentation. The ability to load and render a subset of a VBO or texture means that data loaded doesn't have to match the size of the allocated buffer; as long as it's smaller, it will work.</div><div id="wwpID0EOHA" class="Body_Text">This approach does waste space, in that some of the allocated buffer isn't used, but this waste is often offset by the saving in reduced fragmentation and fixed allocation overhead. This approach can often be combined with approach (2) (combining multiple objects into one allocated buffer) to reduce total wastage. Generally, it's safe to ignore wastage it it's a small percentage of the allocated buffer size (say &lt; 5%).</div><div id="wwpID0ENHA" class="Body_Text">This approach is particularly good for dynamically allocated data, since fixed size blocks can often be freed and reallocated with little or no fragmentation. If wastage is excessive, a set of buffer sizes can be chosen (often a consecutive set of power of two sizes), and the smallest free buffer that will contain the data is used.</div><div id="wwpID0EMHA" class="Heading_5">4. Reuse, rather than free and reallocate, buffers whenever possible</div><div id="wwpID0ELHA" class="Body_Text">The ability to reload a previously allocated buffer with new data for both VBOs and textures makes this technique practical. Reuse is particularly important for large buffers; it is often better to create a large buffer at program start, and reuse it during mode switches, etc., even if it requires allocating a larger buffer to handle all possible cases.</div><div id="wwpID0EKHA" class="Heading_5">5. Minimize dynamic allocation</div><div id="wwpID0EJHA" class="Body_Text">If possible, take memory allocation and freeing out of the inner loop of your application. The ability to reuse buffers makes this practical, even for algorithms that require dynamic allocation. Even with reuse, however, it's still better to organize the code to minimize allocations and frees, and to move the remaining ones out of the main code path as much as possible.</div><div id="wwpID0EIHA" class="Heading_5">6. Try to group dynamic allocations</div><div id="wwpID0EHHA" class="Body_Text">If dynamic allocation is mandatory, try to group similar allocations and frees together. Ideally, an allocation of a buffer is followed by freeing it before another allocation happens. This rarely can be done in practice, but combining a group of related allocations is often nearly as effective.</div><div id="wwpID0EGHA" class="Body_Text">Again, allocations and frees should be replaced whenever possible. Grouping them is a last resort.</div><H3 id="wwpID0EFHA" class="Heading_3">Graphics Driver CPU Usage</H3><div id="wwpID0EEHA" class="Body_Text">In some cases, the reported graphics driver CPU usage may be high, but in fact the yield is related to other CPUs. To reduce the reported CPU usage, set the environment variable as follows:</div><div id="wwpID0EDHA" class="Code">$ export __GL_YIELD=USLEEP</div><H3 id="wwpID0ECHA" class="Heading_3">Performance Guidelines</H3><div id="wwpID0EBHA" class="Body_Text">The NVIDIA Jetson system on a chip (SOC) includes an extremely powerful and flexible 3D GPU whose power is well matched to the OpenGL ES APIs.</div></div><div id="page_dates"></div><!-- Related Topics --><!--                --><footer><!-- Disqus --><!--        --><!-- Google Translation --><!--                    --><br /></footer></div></div><input type="hidden" id="preserve_unknown_file_links" value="false"></input><noscript><div id="noscript_warning">This site works best with JavaScript enabled</div></noscript><script type="text/javascript" src="scripts/common.js"></script><script type="text/javascript" src="scripts/page.js"></script><script type="text/javascript" src="scripts/search-client.js"></script><script type="text/javascript" src="scripts/unidata.js"></script><script type="text/javascript" src="scripts/unibreak.js"></script></body></html>